{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18afb768-1864-4311-92a4-7b1c0c47f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f187549-0e60-4153-9376-5fb1cee8f290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a729856-ca92-4e86-bc99-acaa4be61ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the trailing spaces and special characters\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove unwanted characters (keep words and numbers)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in STOPWORDS]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbf30ad-aa4c-4dc6-94a5-9b26b33e270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_resume_corpus(resume_texts):\n",
    "    \"\"\"\n",
    "    resume_texts: list of resume strings\n",
    "    returns: list of cleaned resume strings\n",
    "    \"\"\"\n",
    "    cleaned_resumes = [clean_text(resume) for resume in resume_texts]\n",
    "    return cleaned_resumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb12c689-0116-4489-be4a-fe0484411224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_jd_corpus(jd_df):\n",
    "    \"\"\"\n",
    "    jd_df: pandas DataFrame containing the job descriptions and skills columns\n",
    "    returns: list of cleaned JD strings\n",
    "    \"\"\"\n",
    "    combined_texts = (jd_df['Job Description'].fillna('') + ' ' + jd_df['skills'].fillna('')).tolist()\n",
    "    cleaned_jds = [clean_text(jd_text) for jd_text in combined_texts]\n",
    "    return cleaned_jds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ca16f7-60d0-4d34-a783-e322907ab894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 962 resumes.\n",
      "--- Resume 1 ---\n",
      "Skills:\n",
      "* Machine learning, Deep learning, scikit-learn, JavaScript/JQuery, SqlServer\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION GOVERNANCE\n",
      "\n",
      "Organizations, Python, Java, HTML, JavaScript, Python Flask, JAVASCRIPT-, JavaScript/JQuery\n",
      "\n",
      "Experience Sentences:\n",
      "MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\n",
      "\n",
      "TEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year.\n"
     ]
    }
   ],
   "source": [
    "# Path to your resumes file\n",
    "file_path = \"./resume_corpus.txt\"\n",
    "\n",
    "# Read the entire file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split based on the separator used between resumes\n",
    "resume_corpus = text.split('----------------------------------------')\n",
    "\n",
    "# Remove empty strings and strip whitespace\n",
    "resume_corpus = [resume.strip() for resume in resume_corpus if resume.strip()]\n",
    "\n",
    "print(f\"Loaded {len(resume_corpus)} resumes.\")\n",
    "print(resume_corpus[0][:500])  # Print part of the first resume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24d556f3-d591-4333-9df8-c0a260ac5e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resume 1 skills machine learning deep learning scikit learn javascript jquery sqlserver information governance organizations python java html javascript python flask javascript javascript jquery experience sentences multiple data science analytic projects usa clients text analytics motor vehicle customer review data received customer feedback survey data past one year\n",
      "social media managers oversee organizations social media presence create schedule content engage followers analyze social media metrics drive brand awareness engagement social media platforms e g facebook twitter instagram content creation scheduling social media analytics insights community engagement paid social advertising\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load your JD CSV\n",
    "jd_df = pd.read_csv('job_descriptions.csv')\n",
    "\n",
    "# Preprocess\n",
    "cleaned_resumes = preprocess_resume_corpus(resume_corpus)\n",
    "cleaned_jds = preprocess_jd_corpus(jd_df)\n",
    "\n",
    "print(cleaned_resumes[0])  # First cleaned resume\n",
    "print(cleaned_jds[0])      # First cleaned JD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f2e8e-dd71-487c-b85c-337665a4c1d2",
   "metadata": {},
   "source": [
    "<h1>Vectorize Texts using TF-IDF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1cb51f-3138-4fa1-a7b3-8b5f248fcdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "combined_corpus = cleaned_resumes+cleaned_jds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8bd3490-13ff-4790-ba1b-a8d9f9d9176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Vectors Shape: (962, 3846)\n",
      "JD Vectors Shape: (1615940, 3846)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # you can tune max_features\n",
    "\n",
    "# Fit and transform the corpus\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_corpus)\n",
    "\n",
    "# Split back into resumes and JDs\n",
    "resume_vectors = tfidf_matrix[:len(resume_corpus)]\n",
    "jd_vectors = tfidf_matrix[len(resume_corpus):]\n",
    "\n",
    "print(\"Resume Vectors Shape:\", resume_vectors.shape)\n",
    "print(\"JD Vectors Shape:\", jd_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559018f-3b45-48b3-9be3-2d1b0777223d",
   "metadata": {},
   "source": [
    "<h1>Compute Cosine Similarity</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c40ce5c-26a7-4119-b334-f4109143e1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing JD batch 0 to 5000...\n",
      "Processing JD batch 5000 to 10000...\n",
      "Processing JD batch 10000 to 15000...\n",
      "Processing JD batch 15000 to 20000...\n",
      "Processing JD batch 20000 to 25000...\n",
      "Processing JD batch 25000 to 30000...\n",
      "Processing JD batch 30000 to 35000...\n",
      "Processing JD batch 35000 to 40000...\n",
      "Processing JD batch 40000 to 45000...\n",
      "Processing JD batch 45000 to 50000...\n",
      "Processing JD batch 50000 to 55000...\n",
      "Processing JD batch 55000 to 60000...\n",
      "Processing JD batch 60000 to 65000...\n",
      "Processing JD batch 65000 to 70000...\n",
      "Processing JD batch 70000 to 75000...\n",
      "Processing JD batch 75000 to 80000...\n",
      "Processing JD batch 80000 to 85000...\n",
      "Processing JD batch 85000 to 90000...\n",
      "Processing JD batch 90000 to 95000...\n",
      "Processing JD batch 95000 to 100000...\n",
      "Processing JD batch 100000 to 105000...\n",
      "Processing JD batch 105000 to 110000...\n",
      "Processing JD batch 110000 to 115000...\n",
      "Processing JD batch 115000 to 120000...\n",
      "Processing JD batch 120000 to 125000...\n",
      "Processing JD batch 125000 to 130000...\n",
      "Processing JD batch 130000 to 135000...\n",
      "Processing JD batch 135000 to 140000...\n",
      "Processing JD batch 140000 to 145000...\n",
      "Processing JD batch 145000 to 150000...\n",
      "Processing JD batch 150000 to 155000...\n",
      "Processing JD batch 155000 to 160000...\n",
      "Processing JD batch 160000 to 165000...\n",
      "Processing JD batch 165000 to 170000...\n",
      "Processing JD batch 170000 to 175000...\n",
      "Processing JD batch 175000 to 180000...\n",
      "Processing JD batch 180000 to 185000...\n",
      "Processing JD batch 185000 to 190000...\n",
      "Processing JD batch 190000 to 195000...\n",
      "Processing JD batch 195000 to 200000...\n",
      "Processing JD batch 200000 to 205000...\n",
      "Processing JD batch 205000 to 210000...\n",
      "Processing JD batch 210000 to 215000...\n",
      "Processing JD batch 215000 to 220000...\n",
      "Processing JD batch 220000 to 225000...\n",
      "Processing JD batch 225000 to 230000...\n",
      "Processing JD batch 230000 to 235000...\n",
      "Processing JD batch 235000 to 240000...\n",
      "Processing JD batch 240000 to 245000...\n",
      "Processing JD batch 245000 to 250000...\n",
      "Processing JD batch 250000 to 255000...\n",
      "Processing JD batch 255000 to 260000...\n",
      "Processing JD batch 260000 to 265000...\n",
      "Processing JD batch 265000 to 270000...\n",
      "Processing JD batch 270000 to 275000...\n",
      "Processing JD batch 275000 to 280000...\n",
      "Processing JD batch 280000 to 285000...\n",
      "Processing JD batch 285000 to 290000...\n",
      "Processing JD batch 290000 to 295000...\n",
      "Processing JD batch 295000 to 300000...\n",
      "Processing JD batch 300000 to 305000...\n",
      "Processing JD batch 305000 to 310000...\n",
      "Processing JD batch 310000 to 315000...\n",
      "Processing JD batch 315000 to 320000...\n",
      "Processing JD batch 320000 to 325000...\n",
      "Processing JD batch 325000 to 330000...\n",
      "Processing JD batch 330000 to 335000...\n",
      "Processing JD batch 335000 to 340000...\n",
      "Processing JD batch 340000 to 345000...\n",
      "Processing JD batch 345000 to 350000...\n",
      "Processing JD batch 350000 to 355000...\n",
      "Processing JD batch 355000 to 360000...\n",
      "Processing JD batch 360000 to 365000...\n",
      "Processing JD batch 365000 to 370000...\n",
      "Processing JD batch 370000 to 375000...\n",
      "Processing JD batch 375000 to 380000...\n",
      "Processing JD batch 380000 to 385000...\n",
      "Processing JD batch 385000 to 390000...\n",
      "Processing JD batch 390000 to 395000...\n",
      "Processing JD batch 395000 to 400000...\n",
      "Processing JD batch 400000 to 405000...\n",
      "Processing JD batch 405000 to 410000...\n",
      "Processing JD batch 410000 to 415000...\n",
      "Processing JD batch 415000 to 420000...\n",
      "Processing JD batch 420000 to 425000...\n",
      "Processing JD batch 425000 to 430000...\n",
      "Processing JD batch 430000 to 435000...\n",
      "Processing JD batch 435000 to 440000...\n",
      "Processing JD batch 440000 to 445000...\n",
      "Processing JD batch 445000 to 450000...\n",
      "Processing JD batch 450000 to 455000...\n",
      "Processing JD batch 455000 to 460000...\n",
      "Processing JD batch 460000 to 465000...\n",
      "Processing JD batch 465000 to 470000...\n",
      "Processing JD batch 470000 to 475000...\n",
      "Processing JD batch 475000 to 480000...\n",
      "Processing JD batch 480000 to 485000...\n",
      "Processing JD batch 485000 to 490000...\n",
      "Processing JD batch 490000 to 495000...\n",
      "Processing JD batch 495000 to 500000...\n",
      "Processing JD batch 500000 to 505000...\n",
      "Processing JD batch 505000 to 510000...\n",
      "Processing JD batch 510000 to 515000...\n",
      "Processing JD batch 515000 to 520000...\n",
      "Processing JD batch 520000 to 525000...\n",
      "Processing JD batch 525000 to 530000...\n",
      "Processing JD batch 530000 to 535000...\n",
      "Processing JD batch 535000 to 540000...\n",
      "Processing JD batch 540000 to 545000...\n",
      "Processing JD batch 545000 to 550000...\n",
      "Processing JD batch 550000 to 555000...\n",
      "Processing JD batch 555000 to 560000...\n",
      "Processing JD batch 560000 to 565000...\n",
      "Processing JD batch 565000 to 570000...\n",
      "Processing JD batch 570000 to 575000...\n",
      "Processing JD batch 575000 to 580000...\n",
      "Processing JD batch 580000 to 585000...\n",
      "Processing JD batch 585000 to 590000...\n",
      "Processing JD batch 590000 to 595000...\n",
      "Processing JD batch 595000 to 600000...\n",
      "Processing JD batch 600000 to 605000...\n",
      "Processing JD batch 605000 to 610000...\n",
      "Processing JD batch 610000 to 615000...\n",
      "Processing JD batch 615000 to 620000...\n",
      "Processing JD batch 620000 to 625000...\n",
      "Processing JD batch 625000 to 630000...\n",
      "Processing JD batch 630000 to 635000...\n",
      "Processing JD batch 635000 to 640000...\n",
      "Processing JD batch 640000 to 645000...\n",
      "Processing JD batch 645000 to 650000...\n",
      "Processing JD batch 650000 to 655000...\n",
      "Processing JD batch 655000 to 660000...\n",
      "Processing JD batch 660000 to 665000...\n",
      "Processing JD batch 665000 to 670000...\n",
      "Processing JD batch 670000 to 675000...\n",
      "Processing JD batch 675000 to 680000...\n",
      "Processing JD batch 680000 to 685000...\n",
      "Processing JD batch 685000 to 690000...\n",
      "Processing JD batch 690000 to 695000...\n",
      "Processing JD batch 695000 to 700000...\n",
      "Processing JD batch 700000 to 705000...\n",
      "Processing JD batch 705000 to 710000...\n",
      "Processing JD batch 710000 to 715000...\n",
      "Processing JD batch 715000 to 720000...\n",
      "Processing JD batch 720000 to 725000...\n",
      "Processing JD batch 725000 to 730000...\n",
      "Processing JD batch 730000 to 735000...\n",
      "Processing JD batch 735000 to 740000...\n",
      "Processing JD batch 740000 to 745000...\n",
      "Processing JD batch 745000 to 750000...\n",
      "Processing JD batch 750000 to 755000...\n",
      "Processing JD batch 755000 to 760000...\n",
      "Processing JD batch 760000 to 765000...\n",
      "Processing JD batch 765000 to 770000...\n",
      "Processing JD batch 770000 to 775000...\n",
      "Processing JD batch 775000 to 780000...\n",
      "Processing JD batch 780000 to 785000...\n",
      "Processing JD batch 785000 to 790000...\n",
      "Processing JD batch 790000 to 795000...\n",
      "Processing JD batch 795000 to 800000...\n",
      "Processing JD batch 800000 to 805000...\n",
      "Processing JD batch 805000 to 810000...\n",
      "Processing JD batch 810000 to 815000...\n",
      "Processing JD batch 815000 to 820000...\n",
      "Processing JD batch 820000 to 825000...\n",
      "Processing JD batch 825000 to 830000...\n",
      "Processing JD batch 830000 to 835000...\n",
      "Processing JD batch 835000 to 840000...\n",
      "Processing JD batch 840000 to 845000...\n",
      "Processing JD batch 845000 to 850000...\n",
      "Processing JD batch 850000 to 855000...\n",
      "Processing JD batch 855000 to 860000...\n",
      "Processing JD batch 860000 to 865000...\n",
      "Processing JD batch 865000 to 870000...\n",
      "Processing JD batch 870000 to 875000...\n",
      "Processing JD batch 875000 to 880000...\n",
      "Processing JD batch 880000 to 885000...\n",
      "Processing JD batch 885000 to 890000...\n",
      "Processing JD batch 890000 to 895000...\n",
      "Processing JD batch 895000 to 900000...\n",
      "Processing JD batch 900000 to 905000...\n",
      "Processing JD batch 905000 to 910000...\n",
      "Processing JD batch 910000 to 915000...\n",
      "Processing JD batch 915000 to 920000...\n",
      "Processing JD batch 920000 to 925000...\n",
      "Processing JD batch 925000 to 930000...\n",
      "Processing JD batch 930000 to 935000...\n",
      "Processing JD batch 935000 to 940000...\n",
      "Processing JD batch 940000 to 945000...\n",
      "Processing JD batch 945000 to 950000...\n",
      "Processing JD batch 950000 to 955000...\n",
      "Processing JD batch 955000 to 960000...\n",
      "Processing JD batch 960000 to 965000...\n",
      "Processing JD batch 965000 to 970000...\n",
      "Processing JD batch 970000 to 975000...\n",
      "Processing JD batch 975000 to 980000...\n",
      "Processing JD batch 980000 to 985000...\n",
      "Processing JD batch 985000 to 990000...\n",
      "Processing JD batch 990000 to 995000...\n",
      "Processing JD batch 995000 to 1000000...\n",
      "Processing JD batch 1000000 to 1005000...\n",
      "Processing JD batch 1005000 to 1010000...\n",
      "Processing JD batch 1010000 to 1015000...\n",
      "Processing JD batch 1015000 to 1020000...\n",
      "Processing JD batch 1020000 to 1025000...\n",
      "Processing JD batch 1025000 to 1030000...\n",
      "Processing JD batch 1030000 to 1035000...\n",
      "Processing JD batch 1035000 to 1040000...\n",
      "Processing JD batch 1040000 to 1045000...\n",
      "Processing JD batch 1045000 to 1050000...\n",
      "Processing JD batch 1050000 to 1055000...\n",
      "Processing JD batch 1055000 to 1060000...\n",
      "Processing JD batch 1060000 to 1065000...\n",
      "Processing JD batch 1065000 to 1070000...\n",
      "Processing JD batch 1070000 to 1075000...\n",
      "Processing JD batch 1075000 to 1080000...\n",
      "Processing JD batch 1080000 to 1085000...\n",
      "Processing JD batch 1085000 to 1090000...\n",
      "Processing JD batch 1090000 to 1095000...\n",
      "Processing JD batch 1095000 to 1100000...\n",
      "Processing JD batch 1100000 to 1105000...\n",
      "Processing JD batch 1105000 to 1110000...\n",
      "Processing JD batch 1110000 to 1115000...\n",
      "Processing JD batch 1115000 to 1120000...\n",
      "Processing JD batch 1120000 to 1125000...\n",
      "Processing JD batch 1125000 to 1130000...\n",
      "Processing JD batch 1130000 to 1135000...\n",
      "Processing JD batch 1135000 to 1140000...\n",
      "Processing JD batch 1140000 to 1145000...\n",
      "Processing JD batch 1145000 to 1150000...\n",
      "Processing JD batch 1150000 to 1155000...\n",
      "Processing JD batch 1155000 to 1160000...\n",
      "Processing JD batch 1160000 to 1165000...\n",
      "Processing JD batch 1165000 to 1170000...\n",
      "Processing JD batch 1170000 to 1175000...\n",
      "Processing JD batch 1175000 to 1180000...\n",
      "Processing JD batch 1180000 to 1185000...\n",
      "Processing JD batch 1185000 to 1190000...\n",
      "Processing JD batch 1190000 to 1195000...\n",
      "Processing JD batch 1195000 to 1200000...\n",
      "Processing JD batch 1200000 to 1205000...\n",
      "Processing JD batch 1205000 to 1210000...\n",
      "Processing JD batch 1210000 to 1215000...\n",
      "Processing JD batch 1215000 to 1220000...\n",
      "Processing JD batch 1220000 to 1225000...\n",
      "Processing JD batch 1225000 to 1230000...\n",
      "Processing JD batch 1230000 to 1235000...\n",
      "Processing JD batch 1235000 to 1240000...\n",
      "Processing JD batch 1240000 to 1245000...\n",
      "Processing JD batch 1245000 to 1250000...\n",
      "Processing JD batch 1250000 to 1255000...\n",
      "Processing JD batch 1255000 to 1260000...\n",
      "Processing JD batch 1260000 to 1265000...\n",
      "Processing JD batch 1265000 to 1270000...\n",
      "Processing JD batch 1270000 to 1275000...\n",
      "Processing JD batch 1275000 to 1280000...\n",
      "Processing JD batch 1280000 to 1285000...\n",
      "Processing JD batch 1285000 to 1290000...\n",
      "Processing JD batch 1290000 to 1295000...\n",
      "Processing JD batch 1295000 to 1300000...\n",
      "Processing JD batch 1300000 to 1305000...\n",
      "Processing JD batch 1305000 to 1310000...\n",
      "Processing JD batch 1310000 to 1315000...\n",
      "Processing JD batch 1315000 to 1320000...\n",
      "Processing JD batch 1320000 to 1325000...\n",
      "Processing JD batch 1325000 to 1330000...\n",
      "Processing JD batch 1330000 to 1335000...\n",
      "Processing JD batch 1335000 to 1340000...\n",
      "Processing JD batch 1340000 to 1345000...\n",
      "Processing JD batch 1345000 to 1350000...\n",
      "Processing JD batch 1350000 to 1355000...\n",
      "Processing JD batch 1355000 to 1360000...\n",
      "Processing JD batch 1360000 to 1365000...\n",
      "Processing JD batch 1365000 to 1370000...\n",
      "Processing JD batch 1370000 to 1375000...\n",
      "Processing JD batch 1375000 to 1380000...\n",
      "Processing JD batch 1380000 to 1385000...\n",
      "Processing JD batch 1385000 to 1390000...\n",
      "Processing JD batch 1390000 to 1395000...\n",
      "Processing JD batch 1395000 to 1400000...\n",
      "Processing JD batch 1400000 to 1405000...\n",
      "Processing JD batch 1405000 to 1410000...\n",
      "Processing JD batch 1410000 to 1415000...\n",
      "Processing JD batch 1415000 to 1420000...\n",
      "Processing JD batch 1420000 to 1425000...\n",
      "Processing JD batch 1425000 to 1430000...\n",
      "Processing JD batch 1430000 to 1435000...\n",
      "Processing JD batch 1435000 to 1440000...\n",
      "Processing JD batch 1440000 to 1445000...\n",
      "Processing JD batch 1445000 to 1450000...\n",
      "Processing JD batch 1450000 to 1455000...\n",
      "Processing JD batch 1455000 to 1460000...\n",
      "Processing JD batch 1460000 to 1465000...\n",
      "Processing JD batch 1465000 to 1470000...\n",
      "Processing JD batch 1470000 to 1475000...\n",
      "Processing JD batch 1475000 to 1480000...\n",
      "Processing JD batch 1480000 to 1485000...\n",
      "Processing JD batch 1485000 to 1490000...\n",
      "Processing JD batch 1490000 to 1495000...\n",
      "Processing JD batch 1495000 to 1500000...\n",
      "Processing JD batch 1500000 to 1505000...\n",
      "Processing JD batch 1505000 to 1510000...\n",
      "Processing JD batch 1510000 to 1515000...\n",
      "Processing JD batch 1515000 to 1520000...\n",
      "Processing JD batch 1520000 to 1525000...\n",
      "Processing JD batch 1525000 to 1530000...\n",
      "Processing JD batch 1530000 to 1535000...\n",
      "Processing JD batch 1535000 to 1540000...\n",
      "Processing JD batch 1540000 to 1545000...\n",
      "Processing JD batch 1545000 to 1550000...\n",
      "Processing JD batch 1550000 to 1555000...\n",
      "Processing JD batch 1555000 to 1560000...\n",
      "Processing JD batch 1560000 to 1565000...\n",
      "Processing JD batch 1565000 to 1570000...\n",
      "Processing JD batch 1570000 to 1575000...\n",
      "Processing JD batch 1575000 to 1580000...\n",
      "Processing JD batch 1580000 to 1585000...\n",
      "Processing JD batch 1585000 to 1590000...\n",
      "Processing JD batch 1590000 to 1595000...\n",
      "Processing JD batch 1595000 to 1600000...\n",
      "Processing JD batch 1600000 to 1605000...\n",
      "Processing JD batch 1605000 to 1610000...\n",
      "Processing JD batch 1610000 to 1615000...\n",
      "Processing JD batch 1615000 to 1615940...\n",
      "Top matches computed.\n",
      "\n",
      "Resume 1 top 5 matches:\n",
      "   JD 328 with similarity score 0.1802\n",
      "   JD 1193 with similarity score 0.1802\n",
      "   JD 2157 with similarity score 0.1802\n",
      "   JD 2226 with similarity score 0.1802\n",
      "   JD 2539 with similarity score 0.1802\n",
      "\n",
      "Resume 2 top 5 matches:\n",
      "   JD 328 with similarity score 0.0457\n",
      "   JD 1193 with similarity score 0.0457\n",
      "   JD 2157 with similarity score 0.0457\n",
      "   JD 2226 with similarity score 0.0457\n",
      "   JD 2539 with similarity score 0.0457\n",
      "\n",
      "Resume 3 top 5 matches:\n",
      "   JD 33 with similarity score 0.0787\n",
      "   JD 88 with similarity score 0.0787\n",
      "   JD 264 with similarity score 0.0787\n",
      "   JD 426 with similarity score 0.0787\n",
      "   JD 1083 with similarity score 0.0787\n",
      "\n",
      "Resume 4 top 5 matches:\n",
      "   JD 328 with similarity score 0.0761\n",
      "   JD 1193 with similarity score 0.0761\n",
      "   JD 2157 with similarity score 0.0761\n",
      "   JD 2226 with similarity score 0.0761\n",
      "   JD 2539 with similarity score 0.0761\n",
      "\n",
      "Resume 5 top 5 matches:\n",
      "   JD 44 with similarity score 0.0544\n",
      "   JD 110 with similarity score 0.0544\n",
      "   JD 186 with similarity score 0.0544\n",
      "   JD 274 with similarity score 0.0544\n",
      "   JD 817 with similarity score 0.0544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 5000  # How many JDs to process at once\n",
    "top_k = 5          # How many top JDs you want per resume\n",
    "\n",
    "n_resumes = resume_vectors.shape[0]\n",
    "n_jds = jd_vectors.shape[0]\n",
    "\n",
    "# To store top-k matches\n",
    "top_matches = [[] for _ in range(n_resumes)]\n",
    "\n",
    "for i in range(0, n_jds, batch_size):\n",
    "    jd_batch = jd_vectors[i:i+batch_size]\n",
    "    print(f\"Processing JD batch {i} to {i + jd_batch.shape[0]}...\")\n",
    "\n",
    "    batch_similarity = cosine_similarity(resume_vectors, jd_batch)  # (962, batch_size)\n",
    "    \n",
    "    for resume_idx in range(n_resumes):\n",
    "        sim_scores = batch_similarity[resume_idx]\n",
    "        jd_indices_in_batch = np.arange(i, i + jd_batch.shape[0])\n",
    "        \n",
    "        # Combine indices and scores\n",
    "        combined = list(zip(jd_indices_in_batch, sim_scores))\n",
    "        \n",
    "        # Extend current matches\n",
    "        top_matches[resume_idx].extend(combined)\n",
    "        \n",
    "        # Keep only top-k highest scores\n",
    "        top_matches[resume_idx] = sorted(top_matches[resume_idx], key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "print(\"Top matches computed.\")\n",
    "\n",
    "# Example of top matches\n",
    "for idx, matches in enumerate(top_matches[:5]):\n",
    "    print(f\"\\nResume {idx+1} top {top_k} matches:\")\n",
    "    for jd_idx, score in matches:\n",
    "        print(f\"   JD {jd_idx} with similarity score {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bdd2c79-0ca3-499e-b17a-cc5029b86def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches saved to top_matches.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Prepare the top_matches in a serializable format\n",
    "serializable_matches = []\n",
    "\n",
    "for resume_idx, matches in enumerate(top_matches):\n",
    "    serializable_matches.append({\n",
    "        \"resume_index\": resume_idx,\n",
    "        \"top_matches\": [\n",
    "            {\"jd_index\": int(jd_idx), \"similarity_score\": float(score)}\n",
    "            for jd_idx, score in matches\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# Save to a JSON file\n",
    "output_path = \"top_matches.json\"\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(serializable_matches, f, indent=4)\n",
    "\n",
    "print(f\"Top matches saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a053f08f-f063-4385-8a9d-fcf74cf9c1b5",
   "metadata": {},
   "source": [
    "<h1>Rank the matches</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "486956c2-3f53-4b7c-afbc-4396580c18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranked matches for Resume 1:\n",
      "JD 328 with similarity score 0.1802\n",
      "JD 1193 with similarity score 0.1802\n",
      "JD 2157 with similarity score 0.1802\n",
      "JD 2226 with similarity score 0.1802\n",
      "JD 2539 with similarity score 0.1802\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Rank JDs for each resume by similarity score\n",
    "ranked_matches = {}\n",
    "\n",
    "# Rank the top-k matches for each resume\n",
    "for entry in serializable_matches:\n",
    "    resume_idx = entry[\"resume_index\"]\n",
    "    \n",
    "    # Sort matches by similarity score (descending)\n",
    "    sorted_matches = sorted(entry[\"top_matches\"], key=lambda x: x[\"similarity_score\"], reverse=True)\n",
    "    \n",
    "    ranked_matches[resume_idx] = sorted_matches\n",
    "\n",
    "# Example: Display the ranked matches for a specific resume (e.g., Resume 1)\n",
    "print(f\"\\nRanked matches for Resume 1:\")\n",
    "for match in ranked_matches[0]:\n",
    "    print(f\"JD {match['jd_index']} with similarity score {match['similarity_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bb73e8b-0741-4cb5-b628-6904bc39b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best JD for Resume 1: JD 328 with similarity score 0.1802\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Match the best JD (top-ranked match) to each resume\n",
    "resume_to_best_jd = {}\n",
    "\n",
    "for resume_idx, matches in ranked_matches.items():\n",
    "    # Select the top-ranked JD for each resume (the first match after sorting)\n",
    "    best_match = matches[0]\n",
    "    resume_to_best_jd[resume_idx] = {\n",
    "        \"jd_index\": best_match[\"jd_index\"],\n",
    "        \"similarity_score\": best_match[\"similarity_score\"]\n",
    "    }\n",
    "\n",
    "# Example: Display the best match for a specific resume (e.g., Resume 1)\n",
    "print(f\"\\nBest JD for Resume 1: JD {resume_to_best_jd[0]['jd_index']} with similarity score {resume_to_best_jd[0]['similarity_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81806a1-be0d-411d-a6ca-af7118241fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 962 resumes.\n",
      "--- Resume 1 ---\n",
      "Skills:\n",
      "* Machine learning, Deep learning, scikit-learn, JavaScript/JQuery, SqlServer\n",
      "\n",
      "\n",
      "\n",
      "INFORMATION GOVERNANCE\n",
      "\n",
      "Organizations, Python, Java, HTML, JavaScript, Python Flask, JAVASCRIPT-, JavaScript/JQuery\n",
      "\n",
      "Experience Sentences:\n",
      "MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\n",
      "\n",
      "TEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the spaCy NER model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Path to your resumes file\n",
    "resume_file_path = \"./resume_corpus.txt\"\n",
    "\n",
    "# Read the entire file\n",
    "with open(resume_file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split based on the separator used between resumes\n",
    "resume_corpus = text.split('----------------------------------------')\n",
    "\n",
    "# Remove empty strings and strip whitespace\n",
    "resume_corpus = [resume.strip() for resume in resume_corpus if resume.strip()]\n",
    "\n",
    "print(f\"Loaded {len(resume_corpus)} resumes.\")\n",
    "print(resume_corpus[0][:500])  # Print part of the first resume\n",
    "\n",
    "# Load your JD CSV\n",
    "jd_df = pd.read_csv('job_descriptions.csv')\n",
    "\n",
    "# Function to extract skills using NER (via spaCy)\n",
    "def extract_skills_with_ner(text):\n",
    "    doc = nlp(text)\n",
    "    # Extract entities that are relevant to skills, we assume 'ORG' for organizations, and 'SKILL' for skills\n",
    "    skills = set()\n",
    "    \n",
    "    # For the sake of example, consider entities like \"ORG\" or \"WORK_OF_ART\" as possible skill indicators\n",
    "    # You can refine this logic further based on your needs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['ORG', 'PRODUCT', 'WORK_OF_ART']:  # Adjust entity types as necessary\n",
    "            skills.add(ent.text.lower())\n",
    "    \n",
    "    return skills\n",
    "\n",
    "# Perform Skill Gap Analysis for each resume and JD\n",
    "gap_analysis_results = []\n",
    "\n",
    "for resume_idx, resume_text in enumerate(resume_corpus):\n",
    "    # Extract skills from the resume\n",
    "    resume_skills = extract_skills_with_ner(resume_text)\n",
    "    \n",
    "    for jd_idx, jd_row in jd_df.iterrows():\n",
    "        # Convert JD skills (string) to a set (split by commas if necessary)\n",
    "        jd_skills = set(jd_row['skills'].lower().split(','))  # Assuming skills are comma-separated in the 'skills' column\n",
    "        \n",
    "        # Perform skill gap analysis: Find skills in JD but not in resume\n",
    "        missing_skills = jd_skills - resume_skills\n",
    "        \n",
    "        # Store the results for this resume-JD pair\n",
    "        gap_analysis_results.append({\n",
    "            \"resume_index\": resume_idx,\n",
    "            \"jd_index\": jd_idx,\n",
    "            \"missing_skills\": list(missing_skills)\n",
    "        })\n",
    "\n",
    "# Display the results (for example, for the first resume and JD)\n",
    "for result in gap_analysis_results[:5]:  # Displaying the first 5 results\n",
    "    print(f\"\\nResume {result['resume_index'] + 1} vs JD {result['jd_index'] + 1}:\")\n",
    "    print(f\"Missing Skills: {', '.join(result['missing_skills'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249169a-5ddb-4e9a-8011-a81279228b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
